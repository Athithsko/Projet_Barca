{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97d18b3-d3f6-40db-b1d6-7af3d8681f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T13:03:23.618266Z",
     "iopub.status.busy": "2025-11-25T13:03:23.617963Z",
     "iopub.status.idle": "2025-11-25T13:03:25.215854Z",
     "shell.execute_reply": "2025-11-25T13:03:25.215386Z",
     "shell.execute_reply.started": "2025-11-25T13:03:23.618187Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Dataset Shape: 38 matches, 13 columns\n",
      "Columns: ['Date', 'Time', 'Round', 'Day', 'Venue', 'Result', 'GF', 'GA', 'Opponent', 'xG', 'xGA', 'Poss', 'Equipe_type']\n",
      "\n",
      "First 5 matches preview:\n",
      "         Date   Time        Round  Day  Venue Result  GF  GA        Opponent  \\\n",
      "0  17.08.2024  21:30  Matchweek 1  Sat      1      W   2   1        Valencia   \n",
      "1  24.08.2024  19:00  Matchweek 2  Sat      0      W   2   1   Athletic Club   \n",
      "2  27.08.2024  21:30  Matchweek 3  Tue      1      W   2   1  Rayo Vallecano   \n",
      "3  31.08.2024  17:00  Matchweek 4  Sat      0      W   7   0      Valladolid   \n",
      "4  15.09.2024  16:15  Matchweek 5  Sun      1      W   4   1          Girona   \n",
      "\n",
      "    xG  xGA  Poss  Equipe_type  \n",
      "0  3,2    1    63            0  \n",
      "1  1,8    1    64            1  \n",
      "2  1,4  0,4    64            1  \n",
      "3  4,7  0,5    70            1  \n",
      "4  1,9  1,3    55            1  \n",
      "\n",
      "----------------------------------------\n",
      "Results distribution\n",
      "----------------------------------------\n",
      "W    28\n",
      "L     6\n",
      "D     4\n",
      "Name: Result, dtype: int64\n",
      "Win rate: 73.7%\n",
      "Descriptive Analysis\n",
      "        Poss     GF     GA     xG    xGA  Equipe_type\n",
      "count  38.00  38.00  38.00  38.00  38.00        38.00\n",
      "mean   68.26   2.68   1.03   2.41   1.10         0.47\n",
      "std     6.69   1.74   1.03   1.14   0.76         0.51\n",
      "min    55.00   0.00   0.00   0.60   0.00         0.00\n",
      "25%    63.00   1.00   0.00   1.50   0.50         0.00\n",
      "50%    69.00   2.00   1.00   2.30   0.95         0.00\n",
      "75%    73.75   4.00   1.00   3.12   1.48         1.00\n",
      "max    81.00   7.00   4.00   5.00   3.10         1.00\n",
      "Correlation with victory\n",
      "Victory        1.00\n",
      "GF             0.52\n",
      "xG             0.33\n",
      "Equipe_type    0.21\n",
      "Poss          -0.08\n",
      "xGA           -0.30\n",
      "GA            -0.52\n",
      "Name: Victory, dtype: float64\n",
      "\n",
      "----------------------------------------\n",
      "Home vs Away games\n",
      "----------------------------------------\n",
      "Number of home matches:19\n",
      "Home Win Rate: 73.7%\n",
      "Home Goals by game: 2.63\n",
      "Number of Away matches:19\n",
      "Away Win Rate: 73.7%\n",
      "Away Goals by game: 2.74\n",
      "\n",
      "----------------------------------------\n",
      "xG efficiency analysis\n",
      "Overall xG Efficiency: 1.20\n",
      "Overall xGA Efficiency: 0.99\n",
      "\n",
      "----------------------------------------\n",
      "key of the analysis\n",
      "----------------------------------------\n",
      "Strongest Victory Predictor: GF (r=0.516)\n",
      "Home Advantage: +0.0% win rate\n",
      "Best xG Efficiency: 3.330\n",
      "\n",
      "======================================================================\n",
      "Analysis finished\n",
      "======================================================================\n",
      "Features used: ['Equipe_type', 'xG', 'xGA', 'Poss', 'Venue', 'Opponent_tier', 'xG_efficiency', 'xGA_efficiency']\n",
      "Training set: 30 matches (first 30 matches)\n",
      "Test set: 8 matches (last 8 matches)\n",
      "\n",
      "======================================================================\n",
      "Ml model results\n",
      "======================================================================\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy:  0.750\n",
      "Precision: 1.000\n",
      "Recall:    0.714\n",
      "F1-Score:  0.833\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy:  0.750\n",
      "Precision: 0.857\n",
      "Recall:    0.857\n",
      "F1-Score:  0.857\n",
      "\n",
      "Feature Importance:\n",
      "       feature  importance\n",
      "xGA_efficiency    0.214783\n",
      " xG_efficiency    0.182281\n",
      "           xGA    0.169904\n",
      "            xG    0.133251\n",
      "          Poss    0.128279\n",
      " Opponent_tier    0.077812\n",
      "   Equipe_type    0.066416\n",
      "         Venue    0.027274\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "Accuracy:  0.875\n",
      "Precision: 0.875\n",
      "Recall:    1.000\n",
      "F1-Score:  0.933\n",
      "\n",
      "Feature Importance:\n",
      "       feature  importance\n",
      " xG_efficiency    0.338624\n",
      "xGA_efficiency    0.291828\n",
      "           xGA    0.259259\n",
      "            xG    0.068598\n",
      "          Poss    0.041690\n",
      "   Equipe_type    0.000000\n",
      "         Venue    0.000000\n",
      " Opponent_tier    0.000000\n",
      "\n",
      "================================================================================\n",
      "Predictions vs Reality\n",
      "================================================================================\n",
      "\n",
      "Match by match comparision:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Legan√©s (Home)\n",
      "   Actual: W (1-0) | xG: 1.4-0.7\n",
      "   Logistic Regression: True Win (prob: 0.95)\n",
      "   Random Forest: True Win (prob: 0.86)\n",
      "   Gradient Boosting: True Win (prob: 1.00)\n",
      "\n",
      " Celta Vigo (Away)\n",
      "   Actual: W (4-3) | xG: 2.9-2.1\n",
      "   Logistic Regression: False Loss/Draw (prob: 0.30)\n",
      "   Random Forest: True Win (prob: 0.64)\n",
      "   Gradient Boosting: True Win (prob: 0.85)\n",
      "\n",
      " Mallorca (Away)\n",
      "   Actual: W (1-0) | xG: 3.3-0.3\n",
      "   Logistic Regression: True Win (prob: 0.90)\n",
      "   Random Forest: True Win (prob: 0.58)\n",
      "   Gradient Boosting: True Win (prob: 0.70)\n",
      "\n",
      " Valladolid (Home)\n",
      "   Actual: W (2-1) | xG: 1.9-0.6\n",
      "   Logistic Regression: False Loss/Draw (prob: 0.38)\n",
      "   Random Forest: False Loss/Draw (prob: 0.45)\n",
      "   Gradient Boosting: True Win (prob: 1.00)\n",
      "\n",
      " Real Madrid (Away)\n",
      "   Actual: W (4-3) | xG: 4.2-2.7\n",
      "   Logistic Regression: True Win (prob: 0.54)\n",
      "   Random Forest: True Win (prob: 0.56)\n",
      "   Gradient Boosting: True Win (prob: 0.85)\n",
      "\n",
      " Espanyol (Home)\n",
      "   Actual: W (2-0) | xG: 0.6-1.4\n",
      "   Logistic Regression: True Win (prob: 0.96)\n",
      "   Random Forest: True Win (prob: 0.65)\n",
      "   Gradient Boosting: True Win (prob: 1.00)\n",
      "\n",
      " Villarreal (Away)\n",
      "   Actual: L (2-3) | xG: 1.4-1.8\n",
      "   Logistic Regression: True Loss/Draw (prob: 0.45)\n",
      "   Random Forest: False Win (prob: 0.75)\n",
      "   Gradient Boosting: False Win (prob: 1.00)\n",
      "\n",
      " Athletic Club (Home)\n",
      "   Actual: W (3-0) | xG: 3.5-1.2\n",
      "   Logistic Regression: True Win (prob: 0.77)\n",
      "   Random Forest: True Win (prob: 0.88)\n",
      "   Gradient Boosting: True Win (prob: 1.00)\n",
      "\n",
      "================================================================================\n",
      "Prediction summary\n",
      "================================================================================\n",
      "\n",
      "Logistic Regression:\n",
      "  Correct predictions: 6/8\n",
      "  Accuracy: 75.0%\n",
      "  Wrong predictions: 2\n",
      "\n",
      "Random Forest:\n",
      "  Correct predictions: 6/8\n",
      "  Accuracy: 75.0%\n",
      "  Wrong predictions: 2\n",
      "\n",
      "Gradient Boosting:\n",
      "  Correct predictions: 7/8\n",
      "  Accuracy: 87.5%\n",
      "  Wrong predictions: 1\n",
      "Best Model: Gradient Boosting (87.5% accuracy)\n",
      "\n",
      "ML Trainig finish\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('/files/Projet_Barca/')\n",
    "sys.path.append('/files/Projet_Barca/Analysis/')\n",
    "\n",
    "from Team_Data_Loader import load_team_data\n",
    "from Analysis_team import explanatory_analysis\n",
    "from Analysis_team import assign_opponent_tier \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_temporal_split(df, train_size=30):\n",
    "    \"\"\"Split data temporally - first 30 matches for training, last 8 for testing\"\"\"\n",
    "    \n",
    "    # Features for modeling\n",
    "    features = ['Equipe_type', 'xG', 'xGA', 'Poss', 'Venue', 'Opponent_tier', 'xG_efficiency', 'xGA_efficiency']\n",
    "    \n",
    "    # Verify all features exist\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    print(f\"Features used: {available_features}\")\n",
    "    \n",
    "    # Temporal split\n",
    "    train_df = df.head(train_size)\n",
    "    test_df = df.tail(len(df) - train_size)\n",
    "    \n",
    "    X_train = train_df[available_features]\n",
    "    y_train = train_df['Victory']\n",
    "    X_test = test_df[available_features]\n",
    "    y_test = test_df['Victory']\n",
    "    \n",
    "    print(f\"Training set: {len(X_train)} matches (first {train_size} matches)\")\n",
    "    print(f\"Test set: {len(X_test)} matches (last {len(df) - train_size} matches)\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, available_features, test_df\n",
    "\n",
    "def train_ml_models(X_train, X_test, y_train, y_test, feature_names):\n",
    "    \"\"\"Train and evaluate the 3 ML models with temporal split\"\"\"\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Scale features for Logistic Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Ml model results\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        \n",
    "        # Use scaled data for Logistic Regression, raw for tree-based models\n",
    "        if name == 'Logistic Regression':\n",
    "            X_tr = X_train_scaled\n",
    "            X_te = X_test_scaled\n",
    "        else:\n",
    "            X_tr = X_train\n",
    "            X_te = X_test\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_tr, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_te)\n",
    "        y_pred_proba = model.predict_proba(X_te)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall:    {recall:.3f}\")\n",
    "        print(f\"F1-Score:  {f1:.3f}\")\n",
    "        \n",
    "        # Feature importance for tree-based models\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            print(f\"\\nFeature Importance:\")\n",
    "            print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def predict_future_matches(model, scaler, new_data, feature_names, model_name):\n",
    "    \"\"\"Make predictions on new matches\"\"\"\n",
    "    \n",
    "    # Prepare features\n",
    "    X_new = new_data[feature_names]\n",
    "    \n",
    "    # Scale if Logistic Regression\n",
    "    if model_name == 'Logistic Regression':\n",
    "        X_new = scaler.transform(X_new)\n",
    "    \n",
    "    predictions = model.predict(X_new)\n",
    "    probabilities = model.predict_proba(X_new)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "def compare_predictions_with_reality(ml_results, X_test, y_test, test_df):\n",
    "    \"\"\"Compare model predictions with actual results\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Predictions vs Reality\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_data = {\n",
    "        'Actual_Result': y_test,\n",
    "        'Actual_Outcome': test_df['Result']\n",
    "    }\n",
    "    \n",
    "    # Add predictions from each model\n",
    "    for model_name, results in ml_results.items():\n",
    "        comparison_data[f'{model_name}_Pred'] = results['predictions']\n",
    "        comparison_data[f'{model_name}_Prob'] = results['probabilities']\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data, index=test_df.index)\n",
    "    \n",
    "    # Add match information\n",
    "    comparison_df['Opponent'] = test_df['Opponent']\n",
    "    comparison_df['Venue'] = test_df['Venue'].map({1: 'Home', 0: 'Away'})\n",
    "    comparison_df['GF'] = test_df['GF']\n",
    "    comparison_df['GA'] = test_df['GA']\n",
    "    comparison_df['xG'] = test_df['xG']\n",
    "    comparison_df['xGA'] = test_df['xGA']\n",
    "    \n",
    "    # Reorder columns for better readability\n",
    "    cols = ['Opponent', 'Venue', 'Actual_Outcome', 'GF', 'GA', 'xG', 'xGA', 'Actual_Result']\n",
    "    for model_name in ml_results.keys():\n",
    "        cols.extend([f'{model_name}_Pred', f'{model_name}_Prob'])\n",
    "    \n",
    "    comparison_df = comparison_df[cols]\n",
    "    \n",
    "    print(\"\\nMatch by match comparision:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in comparison_df.iterrows():\n",
    "        print(f\"\\n {row['Opponent']} ({row['Venue']})\")\n",
    "        print(f\"   Actual: {row['Actual_Outcome']} ({row['GF']}-{row['GA']}) | xG: {row['xG']}-{row['xGA']}\")\n",
    "        \n",
    "        for model_name in ml_results.keys():\n",
    "            pred = row[f'{model_name}_Pred']\n",
    "            prob = row[f'{model_name}_Prob']\n",
    "            correct = \"True\" if pred == row['Actual_Result'] else \"False\"\n",
    "            print(f\"   {model_name}: {correct} {'Win' if pred == 1 else 'Loss/Draw'} (prob: {prob:.2f})\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Prediction summary\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    accuracy_summary = {}\n",
    "    for model_name, results in ml_results.items():\n",
    "        correct_predictions = (results['predictions'] == y_test).sum()\n",
    "        total_predictions = len(y_test)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        \n",
    "        accuracy_summary[model_name] = {\n",
    "            'correct': correct_predictions,\n",
    "            'total': total_predictions,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Correct predictions: {correct_predictions}/{total_predictions}\")\n",
    "        print(f\"  Accuracy: {accuracy:.1%}\")\n",
    "        print(f\"  Wrong predictions: {total_predictions - correct_predictions}\")\n",
    "    \n",
    "    # Best performing model\n",
    "    best_model = max(accuracy_summary.items(), key=lambda x: x[1]['accuracy'])\n",
    "    print(f\"Best Model: {best_model[0]} ({best_model[1]['accuracy']:.1%} accuracy)\")\n",
    "    \n",
    "    return comparison_df, accuracy_summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    team_df = load_team_data()\n",
    "    \n",
    "    # Run explanatory analysis to get processed data with Opponent_tier\n",
    "    results = explanatory_analysis(team_df)\n",
    "    processed_df = results['processed_data']\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Train ML models\n",
    "    X_train, X_test, y_train, y_test, features, test_df = prepare_temporal_split(processed_df)\n",
    "    ml_results = train_ml_models(X_train, X_test, y_train, y_test, features)\n",
    "    comparison_df, accuracy_summary = compare_predictions_with_reality(ml_results, X_test, y_test, test_df)\n",
    "    \n",
    "    print(\"\\nML Trainig finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f73387-0e56-417f-b66b-13b3d99b5ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396553f-c1d9-4efa-864f-230a6ae1c509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
